#!/usr/bin/env python3
"""
Diagnose the prediction error
"""

import sys
import os
sys.path.append('backend')

def check_model_files():
    """Check if model files exist and are readable"""
    print("ğŸ” Checking Model Files")
    print("=" * 40)
    
    model_path = r'C:\Users\USER\Documents\GitHub\sms-spam-detector-ai\models\main_model\clf_model.pkl'
    vectorizer_path = r'C:\Users\USER\Documents\GitHub\sms-spam-detector-ai\models\main_model\vectorizer.pkl'
    
    print(f"ğŸ“ Model path: {model_path}")
    print(f"ğŸ“ Vectorizer path: {vectorizer_path}")
    
    model_exists = os.path.exists(model_path)
    vectorizer_exists = os.path.exists(vectorizer_path)
    
    print(f"âœ… Model exists: {model_exists}")
    print(f"âœ… Vectorizer exists: {vectorizer_exists}")
    
    if model_exists:
        try:
            size = os.path.getsize(model_path)
            print(f"ğŸ“Š Model size: {size} bytes")
        except Exception as e:
            print(f"âŒ Error checking model size: {e}")
    
    if vectorizer_exists:
        try:
            size = os.path.getsize(vectorizer_path)
            print(f"ğŸ“Š Vectorizer size: {size} bytes")
        except Exception as e:
            print(f"âŒ Error checking vectorizer size: {e}")
    
    return model_exists and vectorizer_exists

def test_direct_loading():
    """Test loading models directly"""
    print("\nğŸ”§ Testing Direct Model Loading")
    print("=" * 40)
    
    try:
        import joblib
        
        model_path = r'C:\Users\USER\Documents\GitHub\sms-spam-detector-ai\models\main_model\clf_model.pkl'
        vectorizer_path = r'C:\Users\USER\Documents\GitHub\sms-spam-detector-ai\models\main_model\vectorizer.pkl'
        
        print("Loading model...")
        model = joblib.load(model_path)
        print(f"âœ… Model loaded: {type(model).__name__}")
        
        print("Loading vectorizer...")
        vectorizer = joblib.load(vectorizer_path)
        print(f"âœ… Vectorizer loaded: {type(vectorizer).__name__}")
        
        # Test basic prediction
        test_text = "hello world"
        features = vectorizer.transform([test_text])
        prediction = model.predict(features)[0]
        probabilities = model.predict_proba(features)[0]
        
        print(f"ğŸ§ª Test prediction: {'SPAM' if prediction == 1 else 'HAM'}")
        print(f"ğŸ§ª Test probabilities: {probabilities}")
        
        return True, model, vectorizer
        
    except Exception as e:
        print(f"âŒ Error loading models: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None

def test_nltk_setup():
    """Test NLTK setup"""
    print("\nğŸ”§ Testing NLTK Setup")
    print("=" * 40)
    
    try:
        import nltk
        print("âœ… NLTK imported")
        
        # Test punkt tokenizer
        try:
            nltk.data.find('tokenizers/punkt')
            print("âœ… Punkt tokenizer available")
        except LookupError:
            print("âš ï¸ Punkt tokenizer missing - downloading...")
            nltk.download('punkt')
        
        # Test stopwords
        try:
            nltk.data.find('corpora/stopwords')
            print("âœ… Stopwords available")
        except LookupError:
            print("âš ï¸ Stopwords missing - downloading...")
            nltk.download('stopwords')
        
        # Test tokenization
        from nltk.corpus import stopwords
        from nltk.stem.porter import PorterStemmer
        
        test_text = "This is a test message"
        tokens = nltk.word_tokenize(test_text.lower())
        print(f"ğŸ§ª Test tokenization: {tokens}")
        
        # Test stopwords
        stop_words = stopwords.words('english')
        print(f"ğŸ§ª Stopwords count: {len(stop_words)}")
        
        # Test stemming
        ps = PorterStemmer()
        stemmed = [ps.stem(word) for word in tokens if word.isalnum()]
        print(f"ğŸ§ª Test stemming: {stemmed}")
        
        return True
        
    except Exception as e:
        print(f"âŒ NLTK error: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_spam_detector():
    """Test the SpamDetector class"""
    print("\nğŸ”§ Testing SpamDetector Class")
    print("=" * 40)
    
    try:
        from ml_model.spam_detector import spam_detector
        
        # Check initialization
        print(f"âœ… SpamDetector imported")
        
        # Check model info
        info = spam_detector.get_model_info()
        print(f"ğŸ“Š Model loaded: {info['model_loaded']}")
        print(f"ğŸ“Š Vectorizer loaded: {info['vectorizer_loaded']}")
        print(f"ğŸ“Š NLTK available: {info.get('nltk_available', 'Unknown')}")
        print(f"ğŸ“Š Preprocessing: {info.get('preprocessing', 'Unknown')}")
        
        # Test preprocessing
        test_message = "Hello world this is a test"
        processed = spam_detector.preprocess_text(test_message)
        print(f"ğŸ§ª Preprocessing test:")
        print(f"   Input: {test_message}")
        print(f"   Output: {processed}")
        
        # Test prediction
        print(f"\nğŸ§ª Prediction test:")
        result = spam_detector.predict(test_message)
        print(f"   Result: {result}")
        
        if 'error' in result:
            print(f"âŒ Prediction error: {result.get('error', 'Unknown error')}")
            return False
        else:
            print(f"âœ… Prediction successful: {result['prediction']}")
            return True
        
    except Exception as e:
        print(f"âŒ SpamDetector error: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main diagnostic function"""
    print("ğŸ” SMS Guard Prediction Error Diagnosis")
    print("=" * 60)
    
    # Check model files
    files_ok = check_model_files()
    
    # Test direct loading
    loading_ok, model, vectorizer = test_direct_loading()
    
    # Test NLTK
    nltk_ok = test_nltk_setup()
    
    # Test SpamDetector
    detector_ok = test_spam_detector()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š DIAGNOSIS SUMMARY")
    print("=" * 60)
    
    print(f"âœ… Model Files: {'OK' if files_ok else 'FAILED'}")
    print(f"âœ… Direct Loading: {'OK' if loading_ok else 'FAILED'}")
    print(f"âœ… NLTK Setup: {'OK' if nltk_ok else 'FAILED'}")
    print(f"âœ… SpamDetector: {'OK' if detector_ok else 'FAILED'}")
    
    if all([files_ok, loading_ok, nltk_ok, detector_ok]):
        print("\nğŸ‰ ALL SYSTEMS WORKING!")
        print("The prediction error might be elsewhere.")
    else:
        print("\nğŸ”§ ISSUES FOUND:")
        if not files_ok:
            print("   - Model files missing or inaccessible")
        if not loading_ok:
            print("   - Cannot load models directly")
        if not nltk_ok:
            print("   - NLTK setup problems")
        if not detector_ok:
            print("   - SpamDetector class issues")
        
        print("\nğŸ’¡ RECOMMENDED FIXES:")
        if not files_ok:
            print("   1. Check model file paths")
            print("   2. Ensure models were saved correctly from notebook")
        if not loading_ok:
            print("   3. Retrain and save models from notebook")
        if not nltk_ok:
            print("   4. Install NLTK: pip install nltk")
            print("   5. Download NLTK data")
        if not detector_ok:
            print("   6. Fix SpamDetector initialization")

if __name__ == "__main__":
    main()
